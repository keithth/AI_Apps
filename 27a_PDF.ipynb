{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1c5iBLxrbTSxAnqvnkM5uWsAnxNn17IUT",
      "authorship_tag": "ABX9TyPVRCTd2ueupDRywoSKFGez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keithth/AI_Apps/blob/main/27a_PDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXjVlbPiO-qZ"
      },
      "source": [
        "# Preparing the Colab Environment\n",
        "\n",
        "- [Enable GPU Runtime in Colab](https://docs.haystack.deepset.ai/docs/enabling-gpu-acceleration)\n",
        "- [Set logging level to INFO](https://docs.haystack.deepset.ai/docs/logging)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "G438mI95KATB"
      }
    },
    {
      "source": [
        "!pip uninstall -y haystack-ai pdfminer.six pytesseract numpy"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmbDKI0GDm_G",
        "outputId": "cca1b53e-e2a0-4d77-c51e-0987a6b37a25"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: haystack-ai 2.9.0\n",
            "Uninstalling haystack-ai-2.9.0:\n",
            "  Successfully uninstalled haystack-ai-2.9.0\n",
            "Found existing installation: pdfminer.six 20231228\n",
            "Uninstalling pdfminer.six-20231228:\n",
            "  Successfully uninstalled pdfminer.six-20231228\n",
            "\u001b[33mWARNING: Skipping pytesseract as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: numpy 2.2.2\n",
            "Uninstalling numpy-2.2.2:\n",
            "  Successfully uninstalled numpy-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [bash]\n",
        "# Install the latest Haystack 2.x along with required dependencies.\n",
        "!pip install -qU haystack-ai pydantic\n",
        "!pip install numpy==1.24.4\n",
        "\n",
        "!pip install -qU pdfminer.six==20231228\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aYuWaHnO3Ict",
        "outputId": "64ebff9c-0d13-444c-c5a3-d52e791c1df3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.11/dist-packages (1.24.4)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip show haystack-ai pdfminer.six pytesseract | grep Version | cut -d: -f2"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E12oLXuML2_U",
        "outputId": "b2c115c4-46c7-4cdd-8846-5f548406dffb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Package(s) not found: pytesseract\u001b[0m\u001b[33m\n",
            "\u001b[0m 2.9.0\n",
            " 20231228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key & logs"
      ],
      "metadata": {
        "id": "Gtv7PtzYtO7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "LA6uuYVStiNb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "_nLpBnLGEt8S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test"
      ],
      "metadata": {
        "id": "rHigBujH26_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# %% [python]\n",
        "# Import required modules using the updated paths\n",
        "from haystack.document_stores.in_memory import InMemoryDocumentStore"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1IvP9ODi5nut"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from haystack.components.converters.pdfminer import PDFMinerToDocument\n",
        "from haystack.components.converters.pdfminer import PDFMinerToDocument\n",
        "\n",
        "# converter = PDFMinerToDocument()\n",
        "# results = converter.run(sources=[\"sample.pdf\"], meta={\"date_added\": datetime.now().isoformat()})\n",
        "# documents = results[\"documents\"]\n",
        "# print(documents[0].content)\n",
        "# # 'This is a text from the PDF file.'"
      ],
      "metadata": {
        "id": "kqn5nxGdAY06"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Document\n",
        "from haystack.components.readers import ExtractiveReader"
      ],
      "metadata": {
        "id": "F5P1uMgLJMy7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter"
      ],
      "metadata": {
        "id": "ZeLw3RdxA_oQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from haystack.components.retrievers import InMemoryEmbeddingRetriever"
      ],
      "metadata": {
        "id": "B9Iv6iqUJpJg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from haystack import Document\n",
        "from haystack.components.readers import ExtractiveReader"
      ],
      "metadata": {
        "id": "hlPffdLocCCL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from haystack import Pipeline, Document\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 1: Initialize the DocumentStore\n",
        "# -----------------------------------------------------------------------------\n",
        "document_store = InMemoryDocumentStore()\n"
      ],
      "metadata": {
        "id": "VbQiCSsncGyw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 2: Convert a PDF into Documents\n",
        "# -----------------------------------------------------------------------------\n",
        "# Initialize the PDF converter. Note: PDFToTextConverter now supports parameters like\n",
        "# remove_numeric_tables and valid_languages (see the API reference for PDF converters).\n",
        "pdf_converter = PDFMinerToDocument()\n"
      ],
      "metadata": {
        "id": "y83B0dOT4FUb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# b1"
      ],
      "metadata": {
        "id": "656_kYH0AjrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Update the file path to your PDF file.\n",
        "pdf_file_path = \"/content/drive/MyDrive/A-A-ML/haystack/SEPMSpecialPublication2012Sylvester.pdf\"\n",
        "documents = pdf_converter.convert(file_path=pdf_file_path)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 3: Preprocess the Documents\n",
        "# -----------------------------------------------------------------------------\n",
        "# Clean and split the documents. The old monolithic PreProcessor has been replaced\n",
        "# with dedicated components: DocumentCleaner and DocumentSplitter.\n",
        "cleaner = DocumentCleaner(remove_empty_lines=True, remove_extra_whitespaces=True)\n",
        "splitter = DocumentSplitter(split_by=\"sentence\", split_length=100, split_overlap=10)\n",
        "\n",
        "# First, clean the documents.\n",
        "cleaned_docs = cleaner.run(documents=documents)[\"documents\"]\n",
        "# Then, split the cleaned documents into smaller chunks.\n",
        "processed_docs = splitter.run(documents=cleaned_docs)[\"documents\"]\n",
        "\n",
        "# Write the processed documents into the DocumentStore.\n",
        "document_store.write_documents(processed_docs)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 4: Initialize the Retriever and Update Embeddings\n",
        "# -----------------------------------------------------------------------------\n",
        "# In Haystack 2.x, dense retrievers are now specialized; for an in-memory dense retriever,\n",
        "# use InMemoryEmbeddingRetriever.\n",
        "retriever = InMemoryEmbeddingRetriever(\n",
        "    document_store=document_store,\n",
        "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    use_gpu=True\n",
        ")\n",
        "document_store.update_embeddings(retriever)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 5: Initialize the Reader\n",
        "# -----------------------------------------------------------------------------\n",
        "# Initialize FARMReader using a fine-tuned model.\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 6: Build the Extractive QA Pipeline\n",
        "# -----------------------------------------------------------------------------\n",
        "# Create a new pipeline (Haystack 2.x style uses add_component and connect).\n",
        "pipeline = Pipeline()\n",
        "pipeline.add_component(\"retriever\", retriever)\n",
        "pipeline.add_component(\"reader\", reader)\n",
        "pipeline.connect(\"retriever\", \"reader\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 7: Run a Sample Query\n",
        "# -----------------------------------------------------------------------------\n",
        "query = \"What is seismic stratigraphy?\"\n",
        "result = pipeline.run(data={\n",
        "    \"retriever\": {\"query\": query, \"top_k\": 5},\n",
        "    \"reader\": {\"query\": query, \"top_k\": 3}\n",
        "})\n",
        "\n",
        "# Print the results.\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "OFZP0yzZfQ5H",
        "outputId": "20c26ac2-60c8-4f89-b343-1ade69bb9e60"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'PDFMinerToDocument' object has no attribute 'convert'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-971a5a3f1782>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Update the file path to your PDF file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpdf_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/A-A-ML/haystack/SEPMSpecialPublication2012Sylvester.pdf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpdf_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# -----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PDFMinerToDocument' object has no attribute 'convert'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "S_nPZKFRPezY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NZne4eMIf5mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import updated libraries using the new import paths per the migration guide\n",
        "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
        "from haystack.components.converters import PDFMinerToDocument\n",
        "# from haystack.components.file_converter.pdf import PDFToTextConverter\n",
        "# from haystack.components.preprocessor import PreProcessor\n",
        "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
        "from haystack.components.retrievers import EmbeddingRetriever\n",
        "from haystack.components.readers.farm import FARMReader\n",
        "from haystack import Pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "ytrnfl0f3TJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from haystack.components.file_converter.pdf import PDFToTextConverter"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8CorH8SlGN8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes.file_converter.pdf import PDFToTextConverter\n"
      ],
      "metadata": {
        "id": "z2xzSKHcIWx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional imports for image extraction\n",
        "import pdfplumber\n",
        "import os\n",
        "from PIL import Image\n",
        "import pytesseract\n"
      ],
      "metadata": {
        "id": "U7qQaKBIO7Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def extract_illustrations"
      ],
      "metadata": {
        "id": "vyktV_ygQF6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Define a Function to Extract Illustrations and Captions from the PDF ---\n",
        "def extract_illustrations(pdf_path, output_dir=\"extracted_images\"):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    illustrations = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_num, page in enumerate(pdf.pages, start=1):\n",
        "            # Check if the page contains images\n",
        "            if page.images:\n",
        "                for img in page.images:\n",
        "                    # Extract bounding box (x0, top, x1, bottom)\n",
        "                    bbox = (img['x0'], img['top'], img['x1'], img['bottom'])\n",
        "                    # Convert the page to an image and crop the illustration region\n",
        "                    page_image = page.to_image()\n",
        "                    cropped_image = page_image.crop(bbox).original\n",
        "                    # Save the cropped image to file\n",
        "                    image_filename = os.path.join(output_dir, f\"page_{page_num}_img_{img['object_id']}.png\")\n",
        "                    cropped_image.save(image_filename)\n",
        "                    # Run OCR on the cropped image to extract any caption text\n",
        "                    caption = pytesseract.image_to_string(cropped_image).strip()\n",
        "                    illustrations.append({\n",
        "                        \"page\": page_num,\n",
        "                        \"image_path\": image_filename,\n",
        "                        \"caption\": caption\n",
        "                    })\n",
        "    return illustrations\n"
      ],
      "metadata": {
        "id": "oxwealljQAW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# code1"
      ],
      "metadata": {
        "id": "uIXZWiDHSeIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Initialize the DocumentStore ---\n",
        "document_store = InMemoryDocumentStore()\n",
        "\n",
        "# --- Convert the PDF to Text ---\n",
        "pdf_path = \"/content/drive/MyDrive/A-A-ML/haystack/SEPMSpecialPublication2012Sylvester.pdf\"\n",
        "pdf_converter = PDFToTextConverter(remove_numeric_tables=False, valid_languages=[\"en\"])\n",
        "docs = pdf_converter.convert(file_path=pdf_path)\n",
        "\n",
        "# --- Preprocess the Extracted Text ---\n",
        "preprocessor = PreProcessor(\n",
        "    clean_empty_lines=True,\n",
        "    clean_whitespace=True,\n",
        "    split_by=\"sentence\",\n",
        "    split_length=100,\n",
        "    split_respect_sentence_boundary=True\n",
        ")\n",
        "processed_docs = preprocessor.process(docs)\n",
        "\n",
        "# --- Write Preprocessed Text Documents to the DocumentStore ---\n",
        "document_store.write_documents(processed_docs)\n",
        "\n",
        "# --- Extract Illustrations and Their Captions from the PDF ---\n",
        "illustrations = extract_illustrations(pdf_path)\n",
        "\n",
        "# --- Create \"Illustration\" Documents from the Extracted Data ---\n",
        "illustration_docs = []\n",
        "for ill in illustrations:\n",
        "    # Use the OCR caption if available; otherwise, use a default message.\n",
        "    content = ill[\"caption\"] if ill[\"caption\"] else f\"Illustration from page {ill['page']} (no caption detected)\"\n",
        "    doc = {\n",
        "        \"content\": content,\n",
        "        \"meta\": {\n",
        "            \"type\": \"illustration\",\n",
        "            \"image_path\": ill[\"image_path\"],\n",
        "            \"page\": ill[\"page\"]\n",
        "        }\n",
        "    }\n",
        "    illustration_docs.append(doc)\n",
        "\n",
        "# --- Write Illustration Documents to the DocumentStore ---\n",
        "document_store.write_documents(illustration_docs)\n",
        "\n",
        "# --- Initialize the Retriever ---\n",
        "retriever = EmbeddingRetriever(\n",
        "    document_store=document_store,\n",
        "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    use_gpu=True\n",
        ")\n",
        "document_store.update_embeddings(retriever)\n",
        "\n",
        "# --- Initialize the Reader ---\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)\n",
        "\n",
        "# --- Build the Extractive QA Pipeline ---\n",
        "pipeline = ExtractiveQAPipeline(reader=reader, retriever=retriever)\n"
      ],
      "metadata": {
        "id": "P2TnX1HBSZkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# def summarize_content"
      ],
      "metadata": {
        "id": "UzAwzCJHTS88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Function to Query and Summarize Content ---\n",
        "def summarize_content(query):\n",
        "    result = pipeline.run(\n",
        "        query=query,\n",
        "        params={\"retriever\": {\"top_k\": 15}, \"reader\": {\"top_k\": 5}}\n",
        "    )\n",
        "    summaries = []\n",
        "    for answer in result[\"answers\"]:\n",
        "        summaries.append({\n",
        "            \"Answer\": answer.answer,\n",
        "            \"Score\": answer.score,\n",
        "            \"Context\": answer.context\n",
        "        })\n",
        "    return summaries\n"
      ],
      "metadata": {
        "id": "k5VW5jv1S_7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geological Queries"
      ],
      "metadata": {
        "id": "aB6GEZ9hT1bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Example Geological Queries ---\n",
        "queries = [\n",
        "    \"Summarize the text related to seismic stratigraphy.\",\n",
        "    \"Describe the illustrations and their captions.\",\n",
        "    \"Provide an overview of the key points in the paper.\"\n",
        "]\n",
        "\n",
        "# --- Collect and Display Summaries ---\n",
        "all_summaries = {}\n",
        "for query in queries:\n",
        "    all_summaries[query] = summarize_content(query)\n",
        "\n",
        "for key, summaries in all_summaries.items():\n",
        "    print(f\"\\n{key}:\")\n",
        "    for summary in summaries:\n",
        "        print(f\"Answer: {summary['Answer']}, Score: {summary['Score']}, Context: {summary['Context']}\")\n"
      ],
      "metadata": {
        "id": "lHjmPIyNTwm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# b2"
      ],
      "metadata": {
        "id": "zGSrmbBAV-2F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sq4zprQpkaWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}